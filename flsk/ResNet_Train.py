# -*- coding: utf-8 -*-
"""Copy of Copy of Copy of Copy of Residual_Network_Keras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MHcV1L53u_nD2CaKGrt_O7c9pRD51ByV
"""

# Initial Setup for running notebook in Google Colab

from google.colab import drive
drive.mount('/content/drive')
import os
os.chdir('/content/drive/My Drive/Hackholyoke/resnet_keras')
print(os.getcwd())

# from google.colab import drive
# drive.mount('/content/drive')
# import os
# os.chdir('/content/drive/My Drive/Hackholyoke/Dataset')
# print(os.getcwd())
# import numpy as np

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import os
from urllib.request import urlopen,urlretrieve
from PIL import Image
from tqdm import tqdm_notebook
# %matplotlib inline
from sklearn.utils import shuffle
import cv2
from resnets_utils import *

from keras.models import load_model
from sklearn.datasets import load_files   
from keras.utils import np_utils
from glob import glob
from keras import applications, callbacks
from keras.preprocessing.image import ImageDataGenerator 
from keras import optimizers
from keras.models import Sequential,Model,load_model
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D
from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint

"""### Load the data set"""

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/Hackholyoke/Dataset/Skin_Cancer/hmnist_28_28_RGB.csv', sep = ',')

x = np.array(df.iloc[:,:-1])
y = np.array(df.iloc[:,-1:])

x = x.reshape((x.shape[0], 28, 28, 3))
y = np.squeeze(y)

import cv2
x_orig= []
for i, n in enumerate(x):
  img = Image.fromarray(np.uint8(n))
  x_orig.append(np.array(img.resize((64,64), Image.ANTIALIAS)))
Image.fromarray(np.uint8(x_orig[0]))
y_orig = y

# import numpy as np
# a = np.array([0,1,2,3,4])
# b = np.array([5,6,7,8,9])

# indices = np.arange(a.shape[0])
# print(indices)
# np.random.shuffle(indices)

# a = a[indices]
# b = b[indices]

# print(a)
# print(b)

def shuffle_list(*ls):
  l =list(zip(*ls))
  shuffle(l)
  return zip(*l)

x_orig, y_orig = shuffle_list(x_orig,y_orig)
x_orig = np.array(x_orig)/255.0
x_orig = (x_orig - np.mean(x_orig, axis = 0)) / np.std(x_orig, axis = 0)

total = len(x_orig)
X_train = x_orig[:int(0.8*total)]
y_train_orig = y_orig[:int(0.8*total)]

X_test = x_orig[int(0.8*total):]
y_test_orig = y_orig[int(0.8*total):]

print('X_train', X_train.shape)
print('X_test', X_test.shape)
print('y_train_orig', np.array(y_train_orig).shape)
print('y_test_orig', np.array(y_test_orig).shape)

# Convert training and test labels to one hot matrices
Y_train = convert_to_one_hot(np.array(y_train_orig), 10).T
Y_test = convert_to_one_hot(np.array(y_test_orig), 10).T

print ("number of training examples = " + str(X_train.shape[0]))
print ("number of test examples = " + str(X_test.shape[0]))
print ("X_train shape: " + str(X_train.shape))
print ("Y_train shape: " + str(Y_train.shape))
print ("X_test shape: " + str(X_test.shape))
print ("Y_test shape: " + str(Y_test.shape))

img_height,img_width = 64,64 
num_classes = 10
#If imagenet weights are being loaded, 
#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))
base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))



from keras.optimizers import SGD, Adam
# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)
def generate_random_hyperparams(lr_min, lr_max, do_min, do_max):
    lr = 10**np.random.uniform(lr_min,lr_max)
    do = np.random.uniform(do_min,do_max)
    # reg = 10**np.random.uniform(reg_min,reg_max)
    # hidden = np.random.randint(h_min, h_max)
    return lr, do

# lr =  0.00040033884705718283 do =  0.4737534574775427, for 5000 datapoint, doing good!
# lr =  0.02535465287856519 do =  0.5762909269041454, after fixing seed and 
np.random.seed(0)
for i in range(20):
  print()
  x = base_model.output
  x = GlobalAveragePooling2D()(x)
  lr, do = generate_random_hyperparams(-7, -5, 0.5, 0.6)
  # lr =  0.02535465287856519 
  # do =  0.5762909269041454
  x = Dropout(do)(x) # original = 0.7
  predictions = Dense(num_classes, activation= 'softmax')(x)
  model = Model(inputs = base_model.input, outputs = predictions)
  
  print('i = ', i, 'lr = ',lr, 'do = ', do)
  adam = Adam(lr= lr)
  model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])
  mc = callbacks.ModelCheckpoint("/content/drive/My Drive/Hackholyoke/Results/weights/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)
  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=5, min_lr=1e-8)
  # model.fit(X_train, Y_train, validation_split= 0.2, epochs = 20, batch_size = 64, callbacks = [mc])
  # history = model.fit(X_train[:5000], Y_train[:5000], validation_split= 0.2, epochs = 10, batch_size = 64)
  history = model.fit(X_train, Y_train, validation_data= [X_test, Y_test], epochs = 50, batch_size = 64, callbacks = [mc, reduce_lr])
  # Plot training & validation accuracy values
  plt.plot(history.history['acc'])
  plt.plot(history.history['val_acc'])
  plt.title('Model accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Test'], loc='upper left')
  plt.show()
  plt.savefig('/content/drive/My Drive/Hackholyoke/Results/figures/acc_{}_{}.png'.format(lr, do))

  # Plot training & validation loss values
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('Model loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Test'], loc='upper left')
  plt.show()
  plt.savefig('/content/drive/My Drive/Hackholyoke/Results/figures/loss_{}_{}.png'.format(lr, do))

preds = model.evaluate(X_test, Y_test)
print ("Loss = " + str(preds[0]))
print ("Test Accuracy = " + str(preds[1]))

# model.summary()

a = X_train[0]
print(a.shape)

from PIL import Image

Image.fromarray(np.uint8(a*255))

